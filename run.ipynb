{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in c:\\users\\mohil\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mohil\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: future in c:\\users\\mohil\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\mohil\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\mohil\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\mohil\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohil\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+r\"\\OneDrive\\Desktop\\AI_Crowd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from Network.SDCNet import SDCNet_VGG16_classify\n",
    "from Network.SSDCNet import SSDCNet_classify\n",
    "from utils import VideoStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_path, input_source, SDCNet=True):\n",
    "\n",
    "    if os.path.isfile(input_source):\n",
    "        video_name = input_source.split(\"/\")[-1]\n",
    "        video_path = input_source.replace(video_name,\"\")\n",
    "        print(\"Processing video {} in {}\".format(colored(video_name, 'red'), colored(video_path, 'green')))\n",
    "        cap = cv2.VideoCapture(input_source)\n",
    "    else:\n",
    "        cap = VideoStream(input_source).start()\n",
    "\n",
    "    # --1.2 use initial setting to generate\n",
    "    # set label_indice\n",
    "    label_indice = np.arange(0.5, 22+0.5/2, 0.5)\n",
    "    add = np.array([1e-6, 0.05, 0.10, 0.15, 0.20,\n",
    "                    0.25, 0.30, 0.35, 0.40, 0.45])\n",
    "    label_indice = np.concatenate((add, label_indice))\n",
    "\n",
    "    # init networks\n",
    "    label_indice = torch.Tensor(label_indice)\n",
    "    class_num = len(label_indice)+1\n",
    "\n",
    "    div_times = 2\n",
    "\n",
    "    if SDCNet:\n",
    "        net = SDCNet_VGG16_classify(\n",
    "            class_num, label_indice, load_weights=True).cuda()\n",
    "    else:\n",
    "        net = SSDCNet_classify(class_num, label_indice, div_times=div_times,\n",
    "                               frontend_name='VGG16', block_num=5,\n",
    "                               IF_pre_bn=False, IF_freeze_bn=False, load_weights=True,\n",
    "                               parse_method='maxp').cuda()\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Adding Weights ....\")\n",
    "        all_state_dict = torch.load(model_path)\n",
    "        net.load_state_dict(all_state_dict['net_state_dict'],strict=False)\n",
    "        #model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        net.eval()\n",
    "    else:\n",
    "        print(\"Can't find trained weights!!\")\n",
    "        exit()\n",
    "\n",
    "    first_frame = True\n",
    "  \n",
    "    while True:\n",
    "        flag, image = cap.read()\n",
    "        output_image = np.copy(image)\n",
    "        if first_frame:\n",
    "            rois = cv2.selectROIs(\"frame\", image, False, False)\n",
    "            first_frame = False\n",
    "            # print(roi)\n",
    "        if flag:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "        sum = 0\n",
    "        for roi in rois:\n",
    "            roi_image = image[int(roi[1]):int(roi[1]+roi[3]),\n",
    "                              int(roi[0]):int(roi[0]+roi[2])]\n",
    "\n",
    "            roi_image = cv2.resize(roi_image, (256, 256))\n",
    "\n",
    "            roi_image = np.transpose(roi_image, (2, 0, 1))\n",
    "            roi_image = torch.Tensor(roi_image[None, :, :, :])\n",
    "            # w = image.shape[-1]\n",
    "            # h = image.shape[-2]\n",
    "            # pad_w = 64 - w%64\n",
    "            # padding_left = int(pad_w/2)\n",
    "            # padding_right = pad_w - padding_left\n",
    "            # pad_h = 64 - h%64\n",
    "            # padding_top = int(pad_h/2)\n",
    "            # padding_bottom = pad_h - padding_top\n",
    "            # image = torch.nn.functional.pad(image, (padding_left, padding_right, padding_top, padding_bottom))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                roi_image = roi_image.cuda()\n",
    "            with torch.no_grad():\n",
    "                features = net(roi_image)\n",
    "                div_res = net.resample(features)\n",
    "                merge_res = net.parse_merge(div_res)\n",
    "                if SDCNet:\n",
    "                    outputs = merge_res['div'+str(net.args['div_times'])]\n",
    "                else:\n",
    "                    outputs = merge_res['div'+str(net.div_times)]\n",
    "\n",
    "                del merge_res\n",
    "\n",
    "            cv2.rectangle(output_image, (int(roi[0]), int(roi[1])), (int(\n",
    "                roi[0]+roi[2]), int(roi[1]+roi[3])), (255, 0, 0), thickness=3)\n",
    "            sum += int(outputs.sum().item())\n",
    "\n",
    "        cv2.putText(output_image, \"{}\".format(sum),\n",
    "                    (30, 50), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                    (255, 0, 0), 3)\n",
    "\n",
    "        cv2.imshow(\"frame\", output_image)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cap.release()\n",
    "            exit()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path=r\"C:\\Users\\mohil\\OneDrive\\Desktop\\AI_Crowd\\metero_crowd.mp4\"\n",
    "model_path=r\"C:\\Users\\mohil\\OneDrive\\Desktop\\AI_Crowd\\model\\SHA\\best_epoch.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video \u001b[31mC:\\Users\\mohil\\OneDrive\\Desktop\\AI_Crowd\\metero_crowd.mp4\u001b[0m in \u001b[32m\u001b[0m\n",
      "Adding Weights ....\n"
     ]
    }
   ],
   "source": [
    "main(model_path,input_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
